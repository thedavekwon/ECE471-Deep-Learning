{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(path, transform):\n",
    "    images = [transform(io.imread(os.path.join(path, file))) for file in os.listdir(path)]\n",
    "    labels = [int(file[-5]) for file in os.listdir(path)]\n",
    "    with open(path+\".p\", \"wb\") as f:\n",
    "        pickle.dump({\"images\":images, \"labels\":labels}, f)\n",
    "\n",
    "def load(path):\n",
    "    with open(path+\".p\", \"rb\") as f:\n",
    "        tmp = pickle.load(f)\n",
    "    return tmp[\"images\"], tmp[\"labels\"]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        )\n",
    "save(\"dataset/MNIST/train\", transform)\n",
    "save(\"dataset/MNIST/test\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils import data\n",
    "\n",
    "EPOCH = 20\n",
    "\n",
    "\n",
    "class MNISTDataset(data.Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        self.images, self.labels = load(path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "def load_data():\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    train_set = MNISTDataset(path=\"dataset/MNIST/train\", transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=4096,\n",
    "                                               shuffle=True, num_workers=4)\n",
    "\n",
    "    test_set = MNISTDataset(path=\"dataset/MNIST/test\", transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=4096,\n",
    "                                              shuffle=False, num_workers=4)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 30, 30]              16\n",
      "         MaxPool2d-2            [-1, 8, 15, 15]               0\n",
      "            Conv2d-3           [-1, 16, 15, 15]           1,168\n",
      "         MaxPool2d-4             [-1, 16, 7, 7]               0\n",
      "            Conv2d-5             [-1, 16, 7, 7]           6,416\n",
      "         MaxPool2d-6             [-1, 16, 3, 3]               0\n",
      "            Linear-7                   [-1, 64]           9,280\n",
      "            Linear-8                   [-1, 64]           4,160\n",
      "            Linear-9                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 21,690\n",
      "Trainable params: 21,690\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n",
      "Average loss: 0.000688, Accuracy:1459/10000 (14.59%)\n",
      "Average loss: 0.000670, Accuracy:2973/10000 (29.73%)\n",
      "Average loss: 0.000560, Accuracy:4909/10000 (49.09%)\n",
      "Average loss: 0.000396, Accuracy:6398/10000 (63.980000000000004%)\n",
      "Average loss: 0.000300, Accuracy:6871/10000 (68.71000000000001%)\n",
      "Average loss: 0.000245, Accuracy:7299/10000 (72.99%)\n",
      "Average loss: 0.000217, Accuracy:7647/10000 (76.47%)\n",
      "Average loss: 0.000196, Accuracy:7853/10000 (78.53%)\n",
      "Average loss: 0.000178, Accuracy:8044/10000 (80.44%)\n",
      "Average loss: 0.000163, Accuracy:8251/10000 (82.50999999999999%)\n",
      "Average loss: 0.000149, Accuracy:8418/10000 (84.17999999999999%)\n",
      "Average loss: 0.000134, Accuracy:8602/10000 (86.02%)\n",
      "Average loss: 0.000122, Accuracy:8721/10000 (87.21%)\n",
      "Average loss: 0.000112, Accuracy:8808/10000 (88.08%)\n",
      "Average loss: 0.000103, Accuracy:8900/10000 (89.0%)\n",
      "Average loss: 0.000097, Accuracy:8971/10000 (89.71000000000001%)\n",
      "Average loss: 0.000090, Accuracy:9033/10000 (90.33%)\n",
      "Average loss: 0.000087, Accuracy:9087/10000 (90.86999999999999%)\n",
      "Average loss: 0.000085, Accuracy:9072/10000 (90.72%)\n",
      "Average loss: 0.000081, Accuracy:9159/10000 (91.59%)\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc1 = nn.Linear(144, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        return functools.reduce(lambda a, b: a * b, x.size()[1:])\n",
    "\n",
    "model = Model()\n",
    "model.to(device)\n",
    "summary(model, (1, 28, 28))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f\"[{epoch}, {i + 1}] loss:{running_loss / 2000}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            test_loss += criterion(outputs, target).item()\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    percentage = correct / len(test_loader.dataset)*100\n",
    "    print(f\"Average loss: {test_loss:0.6f}, Accuracy:{correct}/{len(test_loader.dataset)} ({percentage}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 28, 28]               6\n",
      "         MaxPool2d-2            [-1, 3, 14, 14]               0\n",
      "            Conv2d-3            [-1, 3, 12, 12]              84\n",
      "         MaxPool2d-4              [-1, 3, 6, 6]               0\n",
      "            Conv2d-5              [-1, 3, 4, 4]              84\n",
      "         MaxPool2d-6              [-1, 3, 2, 2]               0\n",
      "            Linear-7                   [-1, 10]             130\n",
      "            Linear-8                   [-1, 10]             110\n",
      "            Linear-9                   [-1, 10]             110\n",
      "================================================================\n",
      "Total params: 524\n",
      "Trainable params: 524\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n",
      "Epoch: 1 Average loss: 0.000695, Accuracy:1032/10000 (10.32%)\n",
      "Epoch: 2 Average loss: 0.000694, Accuracy:1032/10000 (10.32%)\n",
      "Epoch: 3 Average loss: 0.000693, Accuracy:1032/10000 (10.32%)\n",
      "Epoch: 4 Average loss: 0.000692, Accuracy:1043/10000 (10.43%)\n",
      "Epoch: 5 Average loss: 0.000690, Accuracy:1053/10000 (10.530000000000001%)\n",
      "Epoch: 6 Average loss: 0.000684, Accuracy:1026/10000 (10.26%)\n",
      "Epoch: 7 Average loss: 0.000667, Accuracy:2669/10000 (26.69%)\n",
      "Epoch: 8 Average loss: 0.000638, Accuracy:2378/10000 (23.78%)\n",
      "Epoch: 9 Average loss: 0.000605, Accuracy:2355/10000 (23.549999999999997%)\n",
      "Epoch: 10 Average loss: 0.000570, Accuracy:2758/10000 (27.58%)\n",
      "Epoch: 11 Average loss: 0.000530, Accuracy:3872/10000 (38.72%)\n",
      "Epoch: 12 Average loss: 0.000480, Accuracy:4406/10000 (44.06%)\n",
      "Epoch: 13 Average loss: 0.000422, Accuracy:4848/10000 (48.480000000000004%)\n",
      "Epoch: 14 Average loss: 0.000372, Accuracy:5438/10000 (54.379999999999995%)\n",
      "Epoch: 15 Average loss: 0.000331, Accuracy:6100/10000 (61.0%)\n",
      "Epoch: 16 Average loss: 0.000293, Accuracy:6672/10000 (66.72%)\n",
      "Epoch: 17 Average loss: 0.000263, Accuracy:7117/10000 (71.17%)\n",
      "Epoch: 18 Average loss: 0.000241, Accuracy:7406/10000 (74.06%)\n",
      "Epoch: 19 Average loss: 0.000225, Accuracy:7577/10000 (75.77000000000001%)\n",
      "Epoch: 20 Average loss: 0.000212, Accuracy:7736/10000 (77.36%)\n",
      "Epoch: 21 Average loss: 0.000203, Accuracy:7830/10000 (78.3%)\n",
      "Epoch: 22 Average loss: 0.000196, Accuracy:7914/10000 (79.14%)\n",
      "Epoch: 23 Average loss: 0.000189, Accuracy:7999/10000 (79.99000000000001%)\n",
      "Epoch: 24 Average loss: 0.000183, Accuracy:8094/10000 (80.94%)\n",
      "Epoch: 25 Average loss: 0.000177, Accuracy:8142/10000 (81.42%)\n",
      "Epoch: 26 Average loss: 0.000171, Accuracy:8198/10000 (81.98%)\n",
      "Epoch: 27 Average loss: 0.000166, Accuracy:8240/10000 (82.39999999999999%)\n",
      "Epoch: 28 Average loss: 0.000162, Accuracy:8285/10000 (82.85%)\n",
      "Epoch: 29 Average loss: 0.000157, Accuracy:8323/10000 (83.23%)\n",
      "Epoch: 30 Average loss: 0.000153, Accuracy:8357/10000 (83.57%)\n",
      "Epoch: 31 Average loss: 0.000149, Accuracy:8398/10000 (83.98%)\n",
      "Epoch: 32 Average loss: 0.000146, Accuracy:8415/10000 (84.15%)\n",
      "Epoch: 33 Average loss: 0.000143, Accuracy:8451/10000 (84.50999999999999%)\n",
      "Epoch: 34 Average loss: 0.000140, Accuracy:8496/10000 (84.96000000000001%)\n",
      "Epoch: 35 Average loss: 0.000137, Accuracy:8526/10000 (85.26%)\n",
      "Epoch: 36 Average loss: 0.000135, Accuracy:8547/10000 (85.47%)\n",
      "Epoch: 37 Average loss: 0.000133, Accuracy:8576/10000 (85.76%)\n",
      "Epoch: 38 Average loss: 0.000132, Accuracy:8601/10000 (86.00999999999999%)\n",
      "Epoch: 39 Average loss: 0.000130, Accuracy:8598/10000 (85.98%)\n",
      "Epoch: 40 Average loss: 0.000128, Accuracy:8636/10000 (86.36%)\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 60\n",
    "\n",
    "class EfficientModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(3, 3, 3)\n",
    "        self.conv3 = nn.Conv2d(3, 3, 3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(12, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 10)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        return functools.reduce(lambda a, b: a * b, x.size()[1:])\n",
    "\n",
    "model = EfficientModel()\n",
    "model.to(device)\n",
    "summary(model, (1, 28, 28))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            test_loss += criterion(outputs, target).item()\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    percentage = correct / len(test_loader.dataset)*100\n",
    "    print(f\"Epoch: {epoch} Average loss: {test_loss:0.6f}, Accuracy:{correct}/{len(test_loader.dataset)} ({percentage}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
