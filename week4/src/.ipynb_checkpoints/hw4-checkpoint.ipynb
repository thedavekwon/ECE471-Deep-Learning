{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def load_CIFAR10_data():\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]\n",
    "    )\n",
    "    train_set = torchvision.datasets.CIFAR10(root='./dataset', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "    train_set, validation_set = data.random_split(train_set,\n",
    "                                                  (int(len(train_set) * 0.9), int(len(train_set) * 0.1)))\n",
    "    test_set = torchvision.datasets.CIFAR10(root='./dataset', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "    train_loader = data.DataLoader(train_set, batch_size=4096,\n",
    "                                   shuffle=True, num_workers=0)\n",
    "    validation_loader = data.DataLoader(validation_set, batch_size=4096,\n",
    "                                        shuffle=True, num_workers=0)\n",
    "    test_loader = data.DataLoader(test_set, batch_size=4096,\n",
    "                                  shuffle=True, num_workers=0)\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    return train_loader, validation_loader, test_loader, classes\n",
    "\n",
    "\n",
    "def load_CIFAR100_data():\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]\n",
    "    )\n",
    "    train_set = torchvision.datasets.CIFAR100(root='./dataset', train=True,\n",
    "                                              download=True, transform=transform)\n",
    "    train_set, validation_set = data.random_split(train_set, (int(len(train_set) * 0.9), int(len(train_set) * 0.1)))\n",
    "    test_set = torchvision.datasets.CIFAR100(root='./dataset', train=False,\n",
    "                                             download=True, transform=transform)\n",
    "\n",
    "    train_loader = data.DataLoader(train_set, batch_size=1024,\n",
    "                                   shuffle=True, num_workers=2)\n",
    "    validation_loader = data.DataLoader(validation_set, batch_size=1024,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "    test_loader = data.DataLoader(test_set, batch_size=1024,\n",
    "                                  shuffle=True, num_workers=2)\n",
    "\n",
    "    return train_loader, validation_loader, test_loader\n",
    "\n",
    "\n",
    "def num_flat_features(x):\n",
    "    return functools.reduce(lambda a, b: a * b, x.size()[1:])\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def accuracy_plot(train_accuracies, accuracies, TEST):\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies)\n",
    "    plt.plot(range(1, len(accuracies) + 1), accuracies)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\\n(%)\").set_rotation(0)\n",
    "\n",
    "    if (TEST):\n",
    "        plt.legend([\"train\", \"test\"])\n",
    "    else:\n",
    "        plt.legend([\"train\", \"validation\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def losses_plot(train_losses, losses, TEST):\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses)\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\").set_rotation(0)\n",
    "\n",
    "    if (TEST):\n",
    "        plt.legend([\"train\", \"test\"])\n",
    "    else:\n",
    "        plt.legend([\"train\", \"validation\"])\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        regularization_loss = 0.0\n",
    "        for param in model.parameters():\n",
    "            regularization_loss += torch.norm(param)\n",
    "        loss = criterion(outputs, y) + LAMBDA * regularization_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    train_percentage = round(correct / len(train_loader.dataset) * 100, 2)\n",
    "    print(f\"Epoch:{epoch} Train Accuracy:{correct}/{len(train_loader.dataset)} ({train_percentage}%)\")\n",
    "    return train_percentage, loss.item()\n",
    "\n",
    "\n",
    "def validate(model, validation_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    vali_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in validation_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = model(X)\n",
    "            vali_loss += criterion(outputs, y).item()\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "    vali_loss /= len(validation_loader.dataset)\n",
    "    vali_percentage = round(correct / len(validation_loader.dataset) * 100, 2)\n",
    "    print(\n",
    "        f\"Epoch:{epoch} Validation loss: {vali_loss:0.6f}, Validation Accuracy:{correct}/{len(validation_loader.dataset)} ({vali_percentage}%)\"\n",
    "    )\n",
    "    return vali_percentage, vali_loss\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = model(X)\n",
    "            test_loss += criterion(outputs, y).item()\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "    test_percentage = round(correct / len(test_loader.dataset) * 100, 2)\n",
    "    print(\n",
    "        f\"Epoch:{epoch} Test loss: {test_loss:0.6f}, Test Accuracy:{correct}/{len(test_loader.dataset)} ({test_percentage}%)\"\n",
    "    )\n",
    "    return test_percentage, test_loss\n",
    "\n",
    "\n",
    "class convLayer(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, pooling_size):\n",
    "        super(convLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size)\n",
    "        self.pooling_size = pooling_size\n",
    "        if self.pooling_size:\n",
    "            self.pool = nn.MaxPool2d(pooling_size)\n",
    "        self.bm = nn.BatchNorm2d(out_channel)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bm(x)\n",
    "        if self.pooling_size:\n",
    "            x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# https://discuss.pytorch.org/t/flatten-layer-of-pytorch-build-by-sequential-container/5983\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10Model, self).__init__()\n",
    "        self.conv1 = convLayer(3, 32, 3, 2)\n",
    "        self.conv2 = convLayer(32, 64, 5, 0)\n",
    "        self.conv3 = convLayer(64, 128, 5, 2)\n",
    "        self.conv4 = convLayer(128, 256, 5, 2)\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = nn.Linear(7744, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 10)\n",
    "        self.layers = [self.conv1, self.conv2, self.flatten, self.fc1, self.fc2, self.fc3]\n",
    "        self.activations = [False, False, False, False, False, True, True, True]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, activation in zip(self.layers, self.activations):\n",
    "            if activation:\n",
    "                x = F.relu(layer(x))\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, validation_loader, test_loader, classes = load_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             896\n",
      "       BatchNorm2d-2           [-1, 32, 30, 30]              64\n",
      "         MaxPool2d-3           [-1, 32, 15, 15]               0\n",
      "           Dropout-4           [-1, 32, 15, 15]               0\n",
      "         convLayer-5           [-1, 32, 15, 15]               0\n",
      "            Conv2d-6           [-1, 64, 11, 11]          51,264\n",
      "       BatchNorm2d-7           [-1, 64, 11, 11]             128\n",
      "           Dropout-8           [-1, 64, 11, 11]               0\n",
      "         convLayer-9           [-1, 64, 11, 11]               0\n",
      "          Flatten-10                 [-1, 7744]               0\n",
      "           Linear-11                 [-1, 4096]      31,723,520\n",
      "           Linear-12                 [-1, 1024]       4,195,328\n",
      "           Linear-13                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 35,981,450\n",
      "Trainable params: 35,981,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.94\n",
      "Params size (MB): 137.26\n",
      "Estimated Total Size (MB): 138.21\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-24b84a1f043b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "EPOCH = 20\n",
    "TEST = True\n",
    "LAMBDA = 0.01\n",
    "\n",
    "model = CIFAR10Model()\n",
    "model.to(device)\n",
    "\n",
    "summary(model, (3, 32, 32))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "train_accuracies = []\n",
    "accuracies = []\n",
    "train_losses = []\n",
    "losses = []\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    acc, loss = train(model, train_loader, optimizer, criterion, device, epoch)\n",
    "    train_accuracies.append(acc)\n",
    "    train_losses.append(loss)\n",
    "    if not TEST:\n",
    "        acc, loss = validate(model, validation_loader, criterion, device, epoch)\n",
    "        accuracies.append(acc)\n",
    "        losses.append(loss)\n",
    "    else:\n",
    "        acc, loss = test(model, validation_loader, criterion, device, epoch)\n",
    "        accuracies.append(acc)\n",
    "        losses.append(loss)\n",
    "plt.figure(1)\n",
    "accuracy_plot(train_accuracies, accuracies, TEST)\n",
    "plt.figure(2)\n",
    "losses_plot(train_losses, losses, TEST)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
